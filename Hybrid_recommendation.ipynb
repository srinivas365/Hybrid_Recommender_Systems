{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Hybrid_recommendation.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxXLnC80F73r",
        "colab_type": "text"
      },
      "source": [
        "# Building a Hybrid Recommendation\n",
        "\n",
        "This notebook contains following sections\n",
        "\n",
        "1. Importing necessary Libraries & dataset\n",
        "2. Building a dataset Module\n",
        "3. Building performance Module\n",
        "4. Building Evaluator Module\n",
        "    1. Evaluated Algorithm submodule\n",
        "    2. Evaluated Data submodule\n",
        "    \n",
        "5. Building Hybrid Module\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3zYKfiQGBxc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08b596e7-f4c7-496c-a9b3-1a76bea9d1b9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChUccfu3JWSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d431e1ff-21d5-46cf-c2f0-327632144efb"
      },
      "source": [
        "!pip install surprise"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: surprise in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.6/dist-packages (from surprise) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (0.14.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.18.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IZ9Pif0-WiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folderpath='drive/My Drive/datasets/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw86W81l4uFs",
        "colab_type": "text"
      },
      "source": [
        "## Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkLFrsUeF73t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import sys\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise import dump\n",
        "\n",
        "from collections import defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRffpPAb5Zl9",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1y-_naXebtRfC6L-5og9DQ3JjrPwQhryn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YMIvXuQ3svj",
        "colab_type": "text"
      },
      "source": [
        "## DataLoader Module\n",
        "\n",
        "This module takes the raw dataset and provides the processed the dataset along with other details \n",
        "\n",
        "It has following functions\n",
        "\n",
        "1. loadDataset\n",
        "2. getUserRating\n",
        "3. getPopularityRanking\n",
        "4. getArtistName\n",
        "5. getArtistID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ntw2QclF73y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#user_id\tartist_mbid\tartist_name\tplays\tnorm_plays\trating\n",
        "\n",
        "class DataLoader:\n",
        "    path='drive/My Drive/datasets/user-songs-rating-3000.csv'\n",
        "    artistID_to_name={}\n",
        "    name_to_artistID={}\n",
        "    #user_id\tartist_mbid\tnorm_plays\trating\n",
        "    \n",
        "    def loadDataset(self):\n",
        "\n",
        "        ratingsDataset = 0\n",
        "        self.artistID_to_name = {}\n",
        "        self.name_to_artistID = {}\n",
        "\n",
        "        reader = Reader(rating_scale=(0, 5))\n",
        "        df_matrix=pd.read_csv(self.path)\n",
        "        #df_matrix=df_matrix.iloc[:200000,:]\n",
        "        ratingsDataset= Dataset.load_from_df(df_matrix[['user_id', 'artist_mbid', 'rating']], reader)\n",
        "    \n",
        "        with open(self.path, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "                artistReader = csv.reader(csvfile)\n",
        "                next(artistReader)  #Skip header line\n",
        "                for row in artistReader:\n",
        "                    artistID = row[1]\n",
        "                    artistName = row[2]\n",
        "                    self.artistID_to_name[artistID] = artistName\n",
        "                    self.name_to_artistID[artistName] = artistID\n",
        "\n",
        "        return ratingsDataset\n",
        "    \n",
        "    def getUserRatings(self, user):\n",
        "        userRatings = []\n",
        "        hitUser = False\n",
        "        with open(self.path, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            ratingReader = csv.reader(csvfile)\n",
        "            next(ratingReader)\n",
        "            for row in ratingReader:\n",
        "                userID = row[0]\n",
        "                if (user == userID):\n",
        "                    artistID = row[1]\n",
        "                    rating = float(row[5])\n",
        "                    userRatings.append((artistID, rating))\n",
        "                    hitUser = True\n",
        "                if (hitUser and (user != userID)):\n",
        "                    break\n",
        "\n",
        "        return userRatings\n",
        "    \n",
        "    def getPopularityRanks(self):\n",
        "        ratings = defaultdict(int)\n",
        "        rankings = defaultdict(int)\n",
        "        with open(self.path, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            ratingReader = csv.reader(csvfile)\n",
        "            next(ratingReader)\n",
        "            for row in ratingReader:\n",
        "                artistID = row[1]\n",
        "                ratings[artistID] += 1\n",
        "        rank = 1\n",
        "        for artistID, ratingCount in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
        "            rankings[artistID] = rank\n",
        "            rank += 1\n",
        "        return rankings\n",
        "    \n",
        "    def getArtistName(self, artistID):\n",
        "        if artistID in self.artistID_to_name:\n",
        "            return self.artistID_to_name[artistID]\n",
        "        else:\n",
        "            return \"\"\n",
        "        \n",
        "    def getArtistID(self, artistName):\n",
        "        if artistName in self.name_to_artistID:\n",
        "            return self.name_to_artistID[artistName]\n",
        "        else:\n",
        "            return 0\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XULXR3ENF74F",
        "colab_type": "text"
      },
      "source": [
        "# performance Class Module\n",
        "\n",
        "This module generated the metrics by taking the predictions of the models.\n",
        "It outputs two metrics\n",
        "1. Mean Absolute Error\n",
        "2. Root mean square Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulim8PeF74G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from surprise import accuracy\n",
        "class PerformanceMetrics:\n",
        "\t\n",
        "\tdef MAE(predictions):\n",
        "\t\treturn accuracy.mae(predictions)\n",
        "\t\t\n",
        "\tdef RMSE(predictions):\n",
        "\t\treturn accuracy.rmse(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYrs_sJ6F74K",
        "colab_type": "text"
      },
      "source": [
        "# ModelBuilder Module\n",
        "\n",
        "This module is to build the algorithms/models to train the dataset\n",
        "It has following models\n",
        "1. getName - returns the name of model\n",
        "2. getModel - returns the model\n",
        "3. saveModel - save the model\n",
        "4. Evaluate - train the model and returns the metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPuqNjifF74N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelBuilder:\n",
        "    def __init__(self, model, name):\n",
        "        self.model = model\n",
        "        self.name = name\n",
        "    def GetName(self):\n",
        "        return self.name\n",
        "    \n",
        "    def GetModel(self):\n",
        "        return self.model\n",
        "\n",
        "    def SaveModel(self,predictions):\n",
        "        \n",
        "        dump.dump(folderpath+self.name,predictions,self.model)\n",
        "        print('Model saved at '+folderpath+self.name)\n",
        "        \n",
        "    \n",
        "    def Evaluate(self, evaluationData,save=False):\n",
        "        metrics = {}\n",
        "        # Compute accuracy\n",
        "    \n",
        "        print(\"Evaluating accuracy...\")\n",
        "        predictions = self.model.fit(evaluationData.GetTrainSet()).test(evaluationData.GetTestSet())\n",
        "        metrics[\"RMSE\"] = PerformanceMetrics.RMSE(predictions)\n",
        "        metrics[\"MAE\"] = PerformanceMetrics.MAE(predictions)\n",
        "        \n",
        "        \n",
        "        print(\"Analysis complete.\")\n",
        "\n",
        "        if(save):\n",
        "            print('saving the model.....')\n",
        "            self.SaveModel(predictions)\n",
        "            \n",
        "    \n",
        "        return metrics\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qcrke_6yF74U",
        "colab_type": "text"
      },
      "source": [
        "# ModelFactory Module\n",
        "\n",
        "This module is used to load a set of models into the returns the metrics/performace of each algorithm\n",
        "\n",
        "It has following functions\n",
        "1. addmodel\n",
        "2. Evaluate\n",
        "3. flushModels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE41k1BhF74V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelFactory:\n",
        "    \n",
        "    models = []\n",
        "    \n",
        "    def __init__(self, dataset):        \n",
        "        ed = DataGenerator(dataset)\n",
        "        self.dataset = ed\n",
        "        self.models=[]\n",
        "        \n",
        "    def AddModel(self, model, name):\n",
        "        alg = ModelBuilder(model, name)\n",
        "        self.models.append(alg)\n",
        "        \n",
        "    def Evaluate(self,save=False):\n",
        "        results = {}\n",
        "        for model in self.models:\n",
        "            print(\"Evaluating \", model.GetName(), \"...\")\n",
        "            results[model.GetName()] = model.Evaluate(self.dataset,save)\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\n\")\n",
        "        print(results)\n",
        "    def flushModels(self):\n",
        "        self.models=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJChMkTQF74Z",
        "colab_type": "text"
      },
      "source": [
        "# DataGenerator Module\n",
        "\n",
        "This model takes the dataset splits it into training dataset and testing dataset and return them "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H44HEWzDF74a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import LeaveOneOut\n",
        "\n",
        "class DataGenerator:\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        #Build a 75/25 train/test split for measuring accuracy\n",
        "        self.trainSet, self.testSet = train_test_split(data, test_size=.25, random_state=1)\n",
        "            \n",
        "    def GetTrainSet(self):\n",
        "        return self.trainSet\n",
        "    \n",
        "    def GetTestSet(self):\n",
        "        return self.testSet\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cndLpPd3hfB",
        "colab_type": "text"
      },
      "source": [
        "# Hybrid Algorithm Module\n",
        "\n",
        "This module takes multiple models along with their preference weights and returns the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i18Xkn3FF74r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from surprise import AlgoBase\n",
        "\n",
        "class HybridModel(AlgoBase):\n",
        "\n",
        "    def __init__(self, models, weights, sim_options={}):\n",
        "        AlgoBase.__init__(self)\n",
        "        self.models = models\n",
        "        self.weights = weights\n",
        "\n",
        "    def fit(self, trainset):\n",
        "        AlgoBase.fit(self, trainset)\n",
        "        \n",
        "        for model in self.models:\n",
        "            model.fit(trainset)\n",
        "                \n",
        "        return self\n",
        "\n",
        "    def estimate(self, user_id, item_id):\n",
        "        \n",
        "        scores_sum = 0\n",
        "        weights_sum = 0\n",
        "        \n",
        "        for i in range(len(self.models)):\n",
        "            scores_sum += self.models[i].estimate(user_id, item_id) * self.weights[i] # 3*1/4+4*3/4 laga ra\n",
        "            weights_sum += self.weights[i] # always becomes one\n",
        "            \n",
        "        return scores_sum / weights_sum\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZmbToKZF74f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LoadData():\n",
        "    ml = DataLoader()\n",
        "    print(\"Loading songs ratings...\")\n",
        "    data = ml.loadDataset()\n",
        "    return (ml, data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xd0gTcdF74j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2543f17-ba3e-42c9-cbb8-84a28cc9025e"
      },
      "source": [
        "# Load up common data set for the recommender algorithms\n",
        "(ml, evaluationData) = LoadData()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading songs ratings...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Bu2zaaF74n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0e9ca051-affd-4811-f8b8-17c69e8a70b2"
      },
      "source": [
        "from surprise import BaselineOnly\n",
        "#Construct an Evaluator to, you know, evaluate them\n",
        "modelfactory = ModelFactory(evaluationData)\n",
        "\n",
        "# BaselineOnly\n",
        "baseline= BaselineOnly()\n",
        "modelfactory.AddModel(baseline, \"baseline\")\n",
        "modelfactory.Evaluate(True)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating  baseline ...\n",
            "Evaluating accuracy...\n",
            "Estimating biases using als...\n",
            "RMSE: 0.9934\n",
            "MAE:  0.6817\n",
            "Analysis complete.\n",
            "saving the model.....\n",
            "Model saved at drive/My Drive/datasets/baseline\n",
            "\n",
            "\n",
            "{'baseline': {'RMSE': 0.9934226190571713, 'MAE': 0.6816700266309835}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vENjQm6daV1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "75c38af0-ebf6-4ed8-fad0-c60e25815ef9"
      },
      "source": [
        "from surprise import SVD\n",
        "# BaselineOnly\n",
        "svd= SVD()\n",
        "modelfactory.AddModel(svd, \"svd\")\n",
        "modelfactory.Evaluate()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating  baseline ...\n",
            "Evaluating accuracy...\n",
            "Estimating biases using als...\n",
            "RMSE: 0.9934\n",
            "MAE:  0.6817\n",
            "Analysis complete.\n",
            "Evaluating  svd ...\n",
            "Evaluating accuracy...\n",
            "RMSE: 1.0063\n",
            "MAE:  0.6831\n",
            "Analysis complete.\n",
            "\n",
            "\n",
            "{'baseline': {'RMSE': 0.9934226190571713, 'MAE': 0.6816700266309835}, 'svd': {'RMSE': 1.0063057804737225, 'MAE': 0.6830706904210475}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_mnLz_6aD8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "3ca37d41-6931-45c4-b0be-b753aa6b537c"
      },
      "source": [
        "#Combine them\n",
        "Hybrid = HybridModel([svd, baseline], [0.5, 0.5])\n",
        "# Fight!\n",
        "modelfactory.AddModel(Hybrid, \"Hybrid\")\n",
        "modelfactory.Evaluate(True)\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating  baseline ...\n",
            "Evaluating accuracy...\n",
            "Estimating biases using als...\n",
            "RMSE: 0.9934\n",
            "MAE:  0.6817\n",
            "Analysis complete.\n",
            "saving the model.....\n",
            "Model saved at drive/My Drive/datasets/baseline\n",
            "Evaluating  svd ...\n",
            "Evaluating accuracy...\n",
            "RMSE: 1.0058\n",
            "MAE:  0.6821\n",
            "Analysis complete.\n",
            "saving the model.....\n",
            "Model saved at drive/My Drive/datasets/svd\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Estimating biases using als...\n",
            "RMSE: 0.9971\n",
            "MAE:  0.6795\n",
            "Analysis complete.\n",
            "saving the model.....\n",
            "Model saved at drive/My Drive/datasets/Hybrid\n",
            "\n",
            "\n",
            "{'baseline': {'RMSE': 0.9934226190571713, 'MAE': 0.6816700266309835}, 'svd': {'RMSE': 1.005848123790534, 'MAE': 0.6821244100215875}, 'Hybrid': {'RMSE': 0.9970686978736479, 'MAE': 0.6794833671716486}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMNhEhlVLmKL",
        "colab_type": "text"
      },
      "source": [
        "# Training dataset using Deep Learing Technique\n",
        "\n",
        "RBMs have two layers, input layer which is also known as visible layer and the hidden layer. The neurons in each layer communicate with neurons in the other layer but not with neurons in the same layer. there is no intralayer communication among the neurons.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqncEa3Ts3Cr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0dda52d1-bf77-40b4-f279-7a48cbace9da"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/datasets/')\n",
        "import RBM \n",
        "import RBMModel\n",
        "\n",
        "import importlib\n",
        "importlib.reload(RBM)\n",
        "importlib.reload(RBMModel)\n",
        "\n",
        "# Construct an Evaluator to, you know, evaluate them\n",
        "deep_factory= ModelFactory(evaluationData)\n",
        "\n",
        "#Simple RBM\n",
        "SimpleRBM = RBMModel.RBMAlgorithm(epochs=10)\n",
        "deep_factory.AddModel(SimpleRBM,'rbm')\n",
        "\n",
        "svd= SVD()\n",
        "deep_factory.AddModel(svd, \"svd\")\n",
        "\n",
        "\n",
        "\n",
        "#Combine them\n",
        "Hybrid = HybridModel([svd, SimpleRBM], [0.5, 0.5])\n",
        "# Fight!\n",
        "deep_factory.AddModel(Hybrid, \"Hybrid\")\n",
        "\n",
        "deep_factory.Evaluate()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating  rbm ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Processing user  300\n",
            "Processing user  350\n",
            "Processing user  400\n",
            "Processing user  450\n",
            "Processing user  500\n",
            "Processing user  550\n",
            "Processing user  600\n",
            "Processing user  650\n",
            "Processing user  700\n",
            "Processing user  750\n",
            "Processing user  800\n",
            "Processing user  850\n",
            "Processing user  900\n",
            "Processing user  950\n",
            "Processing user  1000\n",
            "Processing user  1050\n",
            "Processing user  1100\n",
            "Processing user  1150\n",
            "Processing user  1200\n",
            "Processing user  1250\n",
            "Processing user  1300\n",
            "Processing user  1350\n",
            "Processing user  1400\n",
            "Processing user  1450\n",
            "Processing user  1500\n",
            "Processing user  1550\n",
            "Processing user  1600\n",
            "Processing user  1650\n",
            "Processing user  1700\n",
            "Processing user  1750\n",
            "Processing user  1800\n",
            "Processing user  1850\n",
            "Processing user  1900\n",
            "Processing user  1950\n",
            "Processing user  2000\n",
            "Processing user  2050\n",
            "Processing user  2100\n",
            "Processing user  2150\n",
            "Processing user  2200\n",
            "Processing user  2250\n",
            "Processing user  2300\n",
            "Processing user  2350\n",
            "Processing user  2400\n",
            "Processing user  2450\n",
            "Processing user  2500\n",
            "Processing user  2550\n",
            "Processing user  2600\n",
            "Processing user  2650\n",
            "Processing user  2700\n",
            "Processing user  2750\n",
            "Processing user  2800\n",
            "Processing user  2850\n",
            "Processing user  2900\n",
            "Processing user  2950\n",
            "RMSE: 1.5733\n",
            "MAE:  1.4437\n",
            "Analysis complete.\n",
            "Evaluating  svd ...\n",
            "Evaluating accuracy...\n",
            "RMSE: 1.0070\n",
            "MAE:  0.6827\n",
            "Analysis complete.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Processing user  300\n",
            "Processing user  350\n",
            "Processing user  400\n",
            "Processing user  450\n",
            "Processing user  500\n",
            "Processing user  550\n",
            "Processing user  600\n",
            "Processing user  650\n",
            "Processing user  700\n",
            "Processing user  750\n",
            "Processing user  800\n",
            "Processing user  850\n",
            "Processing user  900\n",
            "Processing user  950\n",
            "Processing user  1000\n",
            "Processing user  1050\n",
            "Processing user  1100\n",
            "Processing user  1150\n",
            "Processing user  1200\n",
            "Processing user  1250\n",
            "Processing user  1300\n",
            "Processing user  1350\n",
            "Processing user  1400\n",
            "Processing user  1450\n",
            "Processing user  1500\n",
            "Processing user  1550\n",
            "Processing user  1600\n",
            "Processing user  1650\n",
            "Processing user  1700\n",
            "Processing user  1750\n",
            "Processing user  1800\n",
            "Processing user  1850\n",
            "Processing user  1900\n",
            "Processing user  1950\n",
            "Processing user  2000\n",
            "Processing user  2050\n",
            "Processing user  2100\n",
            "Processing user  2150\n",
            "Processing user  2200\n",
            "Processing user  2250\n",
            "Processing user  2300\n",
            "Processing user  2350\n",
            "Processing user  2400\n",
            "Processing user  2450\n",
            "Processing user  2500\n",
            "Processing user  2550\n",
            "Processing user  2600\n",
            "Processing user  2650\n",
            "Processing user  2700\n",
            "Processing user  2750\n",
            "Processing user  2800\n",
            "Processing user  2850\n",
            "Processing user  2900\n",
            "Processing user  2950\n",
            "RMSE: 1.1650\n",
            "MAE:  1.0040\n",
            "Analysis complete.\n",
            "\n",
            "\n",
            "{'rbm': {'RMSE': 1.5732653327536739, 'MAE': 1.4437298577219584}, 'svd': {'RMSE': 1.0069576973032366, 'MAE': 0.6826501315236461}, 'Hybrid': {'RMSE': 1.1649843535460234, 'MAE': 1.0040280997374962}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XWLOSnyOSXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}